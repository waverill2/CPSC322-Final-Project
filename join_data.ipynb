{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4961832061068702\n",
      "Error Rate: 0.5038167938931297\n",
      "Precision: 0.49523809523809526\n",
      "Recall: 0.3969465648854962\n",
      "F1 measure: 0.44067796610169496\n",
      "Confusion Matrix: [[312, 212], [316, 208]]\n"
     ]
    }
   ],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "import random\n",
    "importlib.reload(myutils)\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable as mypytable\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "# put data into a table\n",
    "path = os.path.join(\"output_data\", \"batting_fielding_joined.txt\")\n",
    "batting_fielding_joined = mypytable.MyPyTable().load_from_file(path)\n",
    "batting_fielding_joined.drop_column(\"playerID\")\n",
    "table_copy = copy.deepcopy(batting_fielding_joined.data)\n",
    "# print(len(table_copy))\n",
    "# batting_fielding_joined.drop_column('GZ')\n",
    "# print(len(batting_fielding_joined.column_names))\n",
    "# batting_fielding_joined.drop_column('GS')\n",
    "\n",
    "# column = batting_fielding_joined.get_column('E', True)\n",
    "# cutoffs = myutils.compute_equal_width_cutoffs(column, 8)\n",
    "# print(cutoffs)\n",
    "# new_list = []\n",
    "# for value in column:\n",
    "#     if value == max(column):\n",
    "#         new_list.append(8)\n",
    "#     else:\n",
    "#         for i in range(len(cutoffs)-1):\n",
    "#             if cutoffs[i] <= value < cutoffs[i + 1]:\n",
    "#                 new_list.append(i+1)\n",
    "\n",
    "# print(new_list)\n",
    "# for i, row in enumerate(table_copy):\n",
    "#     # row[17] = str(new_list[i])\n",
    "#     row[1] = str(row[1])\n",
    "# batting_fielding_joined.data = table_copy\n",
    "\n",
    "for row in table_copy:\n",
    "    for i in range(len(row)):\n",
    "        row[i] = str(row[i])\n",
    "# print(table_copy)\n",
    "# batting_fielding_joined.data = table_copy\n",
    "# batting_fielding_joined.save_to_file(path)\n",
    "# print(table_copy)\n",
    "\n",
    "rows_of_allstar = []\n",
    "rows_of_nonallstar = []\n",
    "for row in table_copy:\n",
    "    if row[-1] == \"true\":\n",
    "        rows_of_allstar.append(row)\n",
    "    else:\n",
    "        rows_of_nonallstar.append(row)\n",
    "# print(len(rows_of_allstar), len(rows_of_nonallstar))\n",
    "# print(rows_of_nonallstar[1])\n",
    "random.shuffle(rows_of_nonallstar)\n",
    "# print(rows_of_nonallstar[1])\n",
    "new_non_allstar = []\n",
    "for i in range(524):\n",
    "    new_non_allstar.append(rows_of_nonallstar[i])\n",
    "table_copy = rows_of_allstar + new_non_allstar\n",
    "random.shuffle(table_copy)\n",
    "\n",
    "\n",
    "# take the classes col from table and put into y table\n",
    "y = []\n",
    "for instance in table_copy:\n",
    "    y.append(instance[-1])\n",
    "    del(instance[-1])\n",
    "\n",
    "# # create another copy of the dataset\n",
    "table_copy_classifier = copy.deepcopy(table_copy)\n",
    "\n",
    "# # get train and test indices\n",
    "train_indices, test_indices = myevaluation.stratified_kfold_cross_validation(table_copy, y, 10, 0, False)\n",
    "new_table = []\n",
    "indices_to_train = []\n",
    "indices_to_test = []\n",
    "y_train = []\n",
    "predictions = []\n",
    "for i in range(len(train_indices)):\n",
    "    for index in train_indices[i]:\n",
    "        indices_to_train.append(table_copy_classifier[index])\n",
    "        y_train.append(y[index])\n",
    "    for index in test_indices[i]:\n",
    "        indices_to_test.append(table_copy_classifier[index])\n",
    "    dummy_classifier = MyDummyClassifier()\n",
    "    dummy_classifier.fit(indices_to_train, y_train)\n",
    "    predictions.append(dummy_classifier.predict(indices_to_test))\n",
    "    indices_to_train = []\n",
    "    indices_to_test = []\n",
    "    y_train = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for instance in test_indices:\n",
    "    for index in instance:\n",
    "        y_true.append(y[index])\n",
    "for instance in predictions:\n",
    "    for prediction in instance:\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "accuracy = myevaluation.accuracy_score(y_true, y_pred, True)\n",
    "precision = myevaluation.binary_precision_score(y_true, y_pred, [\"false\", \"true\"], \"true\")\n",
    "recall = myevaluation.binary_recall_score(y_true, y_pred, [\"false\", \"true\"], \"true\")\n",
    "f1 = myevaluation.binary_f1_score(y_true, y_pred, [\"false\", \"true\"], \"true\")\n",
    "matrix = myevaluation.confusion_matrix(y_true, y_pred, [\"false\", \"true\"])\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Error Rate: {1-accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 measure: {f1}')\n",
    "print(f'Confusion Matrix: {matrix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6698473282442748\n",
      "Error Rate: 0.33015267175572516\n",
      "Precision: 0.6478405315614618\n",
      "Recall: 0.7442748091603053\n",
      "F1 measure: 0.6927175843694493\n",
      "Confusion Matrix: [[312, 212], [134, 390]]\n"
     ]
    }
   ],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "import random\n",
    "importlib.reload(myutils)\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mypytable as mypytable\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "# put data into a table\n",
    "path = os.path.join(\"output_data\", \"batting_fielding_joined.txt\")\n",
    "batting_fielding_joined = mypytable.MyPyTable().load_from_file(path)\n",
    "batting_fielding_joined.drop_column(\"playerID\")\n",
    "table_copy = copy.deepcopy(batting_fielding_joined.data)\n",
    "# print(len(table_copy))\n",
    "# batting_fielding_joined.drop_column('GZ')\n",
    "# print(len(batting_fielding_joined.column_names))\n",
    "# batting_fielding_joined.drop_column('GS')\n",
    "\n",
    "# column = batting_fielding_joined.get_column('E', True)\n",
    "# cutoffs = myutils.compute_equal_width_cutoffs(column, 8)\n",
    "# print(cutoffs)\n",
    "# new_list = []\n",
    "# for value in column:\n",
    "#     if value == max(column):\n",
    "#         new_list.append(8)\n",
    "#     else:\n",
    "#         for i in range(len(cutoffs)-1):\n",
    "#             if cutoffs[i] <= value < cutoffs[i + 1]:\n",
    "#                 new_list.append(i+1)\n",
    "\n",
    "# print(new_list)\n",
    "# for i, row in enumerate(table_copy):\n",
    "#     # row[17] = str(new_list[i])\n",
    "#     row[1] = str(row[1])\n",
    "# batting_fielding_joined.data = table_copy\n",
    "\n",
    "for row in table_copy:\n",
    "    for i in range(len(row)):\n",
    "        row[i] = str(row[i])\n",
    "# print(table_copy)\n",
    "# batting_fielding_joined.data = table_copy\n",
    "# batting_fielding_joined.save_to_file(path)\n",
    "# print(table_copy)\n",
    "\n",
    "rows_of_allstar = []\n",
    "rows_of_nonallstar = []\n",
    "for row in table_copy:\n",
    "    if row[-1] == \"true\":\n",
    "        rows_of_allstar.append(row)\n",
    "    else:\n",
    "        rows_of_nonallstar.append(row)\n",
    "# print(len(rows_of_allstar), len(rows_of_nonallstar))\n",
    "# print(rows_of_nonallstar[1])\n",
    "random.shuffle(rows_of_nonallstar)\n",
    "# print(rows_of_nonallstar[1])\n",
    "new_non_allstar = []\n",
    "for i in range(524):\n",
    "    new_non_allstar.append(rows_of_nonallstar[i])\n",
    "table_copy = rows_of_allstar + new_non_allstar\n",
    "random.shuffle(table_copy)\n",
    "\n",
    "\n",
    "# take the classes col from table and put into y table\n",
    "y = []\n",
    "for instance in table_copy:\n",
    "    y.append(instance[-1])\n",
    "    del(instance[-1])\n",
    "\n",
    "# # create another copy of the dataset\n",
    "table_copy_classifier = copy.deepcopy(table_copy)\n",
    "\n",
    "# # get train and test indices\n",
    "train_indices, test_indices = myevaluation.stratified_kfold_cross_validation(table_copy, y, 10, 0, False)\n",
    "new_table = []\n",
    "indices_to_train = []\n",
    "indices_to_test = []\n",
    "y_train = []\n",
    "predictions = []\n",
    "for i in range(len(train_indices)):\n",
    "    for index in train_indices[i]:\n",
    "        indices_to_train.append(table_copy_classifier[index])\n",
    "        y_train.append(y[index])\n",
    "    for index in test_indices[i]:\n",
    "        indices_to_test.append(table_copy_classifier[index])\n",
    "    tree_classifier = MyDecisionTreeClassifier()\n",
    "    tree_classifier.fit(indices_to_train, y_train)\n",
    "    predictions.append(tree_classifier.predict(indices_to_test))\n",
    "    indices_to_train = []\n",
    "    indices_to_test = []\n",
    "    y_train = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for instance in test_indices:\n",
    "    for index in instance:\n",
    "        y_true.append(y[index])\n",
    "for instance in predictions:\n",
    "    for prediction in instance:\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "accuracy = myevaluation.accuracy_score(y_true, y_pred, True)\n",
    "precision = myevaluation.binary_precision_score(y_true, y_pred, [\"false\", \"true\"], \"true\")\n",
    "recall = myevaluation.binary_recall_score(y_true, y_pred, [\"false\", \"true\"], \"true\")\n",
    "f1 = myevaluation.binary_f1_score(y_true, y_pred, [\"false\", \"true\"], \"true\")\n",
    "matrix = myevaluation.confusion_matrix(y_true, y_pred, [\"false\", \"true\"])\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Error Rate: {1-accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 measure: {f1}')\n",
    "print(f'Confusion Matrix: {matrix}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "from mypytable import MyPyTable\n",
    "\n",
    "fname = os.path.join(\"input_data\", \"AllstarFull.csv\")\n",
    "allstar_table = MyPyTable().load_from_file(fname)\n",
    "# print(allstar_table.data)\n",
    "\n",
    "fname = os.path.join(\"input_data\", \"Batting.csv\")\n",
    "# batting_table = MyPyTable().load_from_file(fname)\n",
    "# print(batting_table.data)\n",
    "\n",
    "fname = os.path.join(\"input_data\", \"Fielding.csv\")\n",
    "# fielding_table = MyPyTable().load_from_file(fname)\n",
    "# print(fielding_table)\n",
    "\n",
    "fname = os.path.join(\"input_data\", \"player.csv\")\n",
    "player_table = MyPyTable().load_from_file(fname)\n",
    "# print(fielding_table)\n",
    "\n",
    "''' first drop rows from table if they are not in year 2000-2015 '''\n",
    "# use this code for all three datasets\n",
    "# lst_of_indices = [i for i in range(3916)]\n",
    "# allstar_table.drop_rows(lst_of_indices)\n",
    "# allstar_table_clean = os.path.join(\"output_data\", \"Allstar.txt\")\n",
    "# allstar_table.save_to_file(allstar_table_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['weston', 2000, 3, 30], ['weston', 2000, 3, 40]]\n",
      "[['weston', 2000, 6, 70]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import mypytable as mypytable\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "header = ['att1', 'att2']\n",
    "data = [['weston', 1], \n",
    "        ['mike', 2]]\n",
    "\n",
    "header2 = ['att1', 'att4', 'att5', 'att6']\n",
    "data2 = [['weston', 2000,3, 30],\n",
    "         ['weston', 2000, 3, 40]]\n",
    "\n",
    "table1 = mypytable.MyPyTable(header, data)\n",
    "table2 = mypytable.MyPyTable(header2, data2)\n",
    "\n",
    "new_table = []\n",
    "primarykey_list = []\n",
    "for row in table2.data:\n",
    "    key = str(row[0]) + str(row[1])\n",
    "    if key not in primarykey_list:\n",
    "        primarykey_list.append(key)\n",
    "# print(primarykey_list)\n",
    "\n",
    "for key in primarykey_list:\n",
    "    temp_table = []\n",
    "    for instance in table2.data:\n",
    "        temp_key = str(instance[0]) + str(instance[1])\n",
    "        if temp_key == key:\n",
    "            temp_table.append(instance)\n",
    "    if len(temp_table) == 1:\n",
    "        # add a zero to missing values\n",
    "        for i in range(2, len(temp_table[0])):\n",
    "            if type(temp_table[0][i]) != float and type(temp_table[0][i]) != int:\n",
    "                temp_table[0][i] = 0.0\n",
    "        new_table.append(temp_table[0])\n",
    "    else:\n",
    "        print(temp_table)\n",
    "        new_row = temp_table[0]\n",
    "        for i in range(2, len(new_row)):\n",
    "            if type(new_row[i]) != float and type(new_row[i]) != int:\n",
    "                new_row[i] = 0.0\n",
    "        for i in range(1, len(temp_table)):\n",
    "                for j in range(2, len(temp_table[i])):\n",
    "                    if type(temp_table[i][j]) == float or type(temp_table[i][j]) == int:\n",
    "                        new_row[j] += temp_table[i][j]\n",
    "        new_table.append(new_row)\n",
    "table2.data = new_table\n",
    "print(table2.data)\n",
    "            \n",
    "        \n",
    "# joined_table = table1.perform_inner_join(table2, [\"att1\"])\n",
    "# print(joined_table.data)\n",
    "# print(joined_table.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean the batting and fielding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import mypytable as mypytable\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "path = os.path.join(\"output_data\", \"Batting.txt\")\n",
    "batting_table = mypytable.MyPyTable().load_from_file(path)\n",
    "\n",
    "path = os.path.join(\"output_data\", \"Fielding.txt\")\n",
    "fielding_table = mypytable.MyPyTable().load_from_file(path)\n",
    "\n",
    "\n",
    "# new_table = []\n",
    "# primarykey_list = []\n",
    "# for row in fielding_table.data:\n",
    "#     key = str(row[0]) + str(row[1])\n",
    "#     if key not in primarykey_list:\n",
    "#         primarykey_list.append(key)\n",
    "# # print(primarykey_list)\n",
    "\n",
    "# for key in primarykey_list:\n",
    "#     temp_table = []\n",
    "#     for instance in fielding_table.data:\n",
    "#         temp_key = str(instance[0]) + str(instance[1])\n",
    "#         if temp_key == key:\n",
    "#             temp_table.append(instance)\n",
    "#     if len(temp_table) == 1:\n",
    "#         # add a zero to missing values\n",
    "#         for i in range(2, len(temp_table[0])):\n",
    "#             if type(temp_table[0][i]) != float and type(temp_table[0][i]) != int:\n",
    "#                 temp_table[0][i] = 0.0\n",
    "#         new_table.append(temp_table[0])\n",
    "#     else:\n",
    "#         # print(temp_table)\n",
    "#         new_row = temp_table[0]\n",
    "#         for i in range(2, len(new_row)):\n",
    "#             if type(new_row[i]) != float and type(new_row[i]) != int:\n",
    "#                 new_row[i] = 0.0\n",
    "#         for i in range(1, len(temp_table)):\n",
    "#                 for j in range(2, len(temp_table[i])):\n",
    "#                     if type(temp_table[i][j]) == float or type(temp_table[i][j]) == int:\n",
    "#                         new_row[j] += temp_table[i][j]\n",
    "#         new_table.append(new_row)\n",
    "# fielding_table.data = new_table\n",
    "# path = os.path.join(\"output_data\", \"Fielding_clean.txt\")\n",
    "# fielding_table.save_to_file(path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "importlib.reload(myutils)\n",
    "import mypytable as mypytable\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "fname = os.path.join(\"input_data\", \"player.csv\")\n",
    "player_table = MyPyTable().load_from_file(fname)\n",
    "# print(len(player_table.data))\n",
    "indices_to_remove = []\n",
    "# for i, instance in enumerate(player_table.data):\n",
    "#     if int(instance[1]) < 1955:\n",
    "#         indices_to_remove.append(i)\n",
    "# player_table.drop_rows(indices_to_remove)\n",
    "i = 0\n",
    "for i, instance in enumerate(player_table.data):\n",
    "    try:\n",
    "        if instance[1] < 1955:\n",
    "            indices_to_remove.append(i)\n",
    "    except:\n",
    "        indices_to_remove.append(i)\n",
    "# print(len(indices_to_remove))\n",
    "# player_table.drop_rows(indices_to_remove)\n",
    "# print(len(player_table.data))\n",
    "# player_clean = os.path.join(\"output_data\", \"player.txt\")\n",
    "# player_table.save_to_file(player_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are steps for joining the tables from output_data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20115\n",
      "524 19591\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import myutils\n",
    "import mypytable as mypytable\n",
    "importlib.reload(myutils)\n",
    "importlib.reload(mypytable)\n",
    "\n",
    "# path = os.path.join(\"output_data\", \"Batting_clean.txt\")\n",
    "# batting_table = mypytable.MyPyTable().load_from_file(path)\n",
    "\n",
    "# path = os.path.join(\"output_data\", \"Fielding_clean.txt\")\n",
    "# fielding_table = mypytable.MyPyTable().load_from_file(path)\n",
    "\n",
    "# path = os.path.join(\"output_data\", \"player.txt\")\n",
    "# player_table = mypytable.MyPyTable().load_from_file(path)\n",
    "# print(batting_table.column_names)\n",
    "# print(fielding_table.column_names)\n",
    "# print(player_table.column_names)\n",
    "\n",
    "# going to drop some columns in the tables to try and speed up joins\n",
    "# batting_table.drop_column(\"stint\")\n",
    "# batting_table.drop_column(\"teamID\")\n",
    "# batting_table.drop_column(\"CS\")\n",
    "# batting_table.drop_column(\"SH\")\n",
    "# batting_table.drop_column(\"SF\")\n",
    "# batting_table.drop_column(\"GIDP\")\n",
    "# batting_table.drop_column(\"IBB\")\n",
    "# batting_table.drop_column(\"HBP\")\n",
    "# batting_table.drop_column(\"lgID\")\n",
    "# print(batting_table.column_names)\n",
    "\n",
    "# fielding_table.drop_column(\"stint\")\n",
    "# fielding_table.drop_column(\"teamID\")\n",
    "# fielding_table.drop_column(\"lgID\")\n",
    "\n",
    "# fielding_table.drop_column(\"SB\")\n",
    "# fielding_table.drop_column(\"CS\")\n",
    "# fielding_table.drop_column(\"ZR\")\n",
    "\n",
    "# fielding_table.drop_column(\"InnOuts\")\n",
    "# fielding_table.drop_column(\"POS\")\n",
    "# fielding_table.drop_column(\"PB\")\n",
    "\n",
    "# fielding_table.drop_column(\"WP\")\n",
    "# fielding_table.drop_column(\"DP\")\n",
    "# print(fielding_table.column_names)\n",
    "\n",
    "# player_table.drop_column(\"birth_month\")\n",
    "# player_table.drop_column(\"birth_day\")\n",
    "# player_table.drop_column(\"birth_country\")\n",
    "\n",
    "# player_table.drop_column(\"birth_state\")\n",
    "# player_table.drop_column(\"birth_city\")\n",
    "# player_table.drop_column(\"death_year\")\n",
    "\n",
    "# player_table.drop_column(\"death_month\")\n",
    "# player_table.drop_column(\"death_day\")\n",
    "# player_table.drop_column(\"death_country\")\n",
    "\n",
    "# player_table.drop_column(\"death_state\")\n",
    "# player_table.drop_column(\"death_city\")\n",
    "# player_table.drop_column(\"name_given\")\n",
    "# print(player_table.column_names)\n",
    "# path = os.path.join(\"output_data\", \"player.txt\")\n",
    "# player_table.save_to_file(path)\n",
    "\n",
    "\n",
    "# batting_fielding_joined = batting_table.perform_inner_join(fielding_table, [\"playerID\", \"yearID\"])\n",
    "# path = os.path.join(\"output_data\", \"batting_fielding_joined.txt\")\n",
    "# batting_fielding_joined.save_to_file(path)\n",
    "path = os.path.join(\"output_data\", \"batting_fielding_joined.txt\")\n",
    "batting_fielding_joined = mypytable.MyPyTable().load_from_file(path)\n",
    "# print(len(batting_fielding_joined.data))\n",
    "# path = os.path.join(\"output_data\", \"Allstar.txt\")\n",
    "# allstar_table = mypytable.MyPyTable().load_from_file(path)\n",
    "# allstar_dict = {}\n",
    "# for instance in allstar_table.data:\n",
    "#     allstar_dict[instance[0]] = instance[1]\n",
    "# for instance in batting_fielding_joined.data:\n",
    "#     if instance[0] in allstar_dict:\n",
    "#         try:\n",
    "#             if instance[1] == allstar_dict[instance[0]]:\n",
    "#                 instance.append(\"true\")\n",
    "#             else:\n",
    "#                 instance.append(\"false\")\n",
    "#         except:\n",
    "#             instance.append(\"false\")\n",
    "#     else:\n",
    "#         instance.append(\"false\")\n",
    "# batting_fielding_joined.column_names.append('class')\n",
    "# path = os.path.join(\"output_data\", \"batting_fielding_joined.txt\")\n",
    "# batting_fielding_joined.save_to_file(path)\n",
    "\n",
    "\n",
    "# count1 = 0\n",
    "# count2 = 0\n",
    "# for row in batting_fielding_joined.data:\n",
    "#     if row[-1] == \"true\":\n",
    "#         count1+=1\n",
    "#     elif row[-1] == \"false\":\n",
    "#         count2 += 1\n",
    "# print(count1, count2)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98cc8a3e9e9b1e128450920e7c198c9bd6e3908fe3cb16854537f0ebed56a5f5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
